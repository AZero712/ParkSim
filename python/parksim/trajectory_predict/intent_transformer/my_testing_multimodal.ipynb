{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from my_dlp.dataset import Dataset\n",
    "from my_dlp.visualizer import Visualizer, SemanticVisualizer\n",
    "from PIL import Image\n",
    "\n",
    "from parksim.intent_predict.cnn.data_processing.utils import CNNDataProcessor\n",
    "from parksim.trajectory_predict.data_processing.utils import TransformerDataProcessor\n",
    "\n",
    "from parksim.intent_predict.cnn.models.small_regularized_cnn import SmallRegularizedCNN\n",
    "from parksim.trajectory_predict.intent_transformer.models.trajectory_predictor_vision_transformer import TrajectoryPredictorVisionTransformer\n",
    "from parksim.trajectory_predict.intent_transformer.models.trajectory_predictor_with_decoder_intent_cross_attention import TrajectoryPredictorWithDecoderIntentCrossAttention\n",
    "\n",
    "from parksim.trajectory_predict.intent_transformer.multimodal_prediction import predict_multimodal\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset()\n",
    "\n",
    "home_path = str(Path.home()) \n",
    "ds.load(home_path + '/dlp-dataset/data/DJI_0012')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SmallRegularizedCNN(\n",
       "  (image_layer): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 8, kernel_size=(7, 7), stride=(1, 1))\n",
       "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(8, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (flatten_layer): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (linear_layer1): Sequential(\n",
       "    (0): Linear(in_features=6632, out_features=100, bias=True)\n",
       "    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (linear_layer2): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = '/root/SUSTC_Parking_test/ParkSim/data/epoch=52-val_total_loss=0.0458.ckpt'\n",
    "traj_model = TrajectoryPredictorWithDecoderIntentCrossAttention.load_from_checkpoint(MODEL_PATH)\n",
    "traj_model.eval().to(DEVICE)\n",
    "mode='v1'\n",
    "\n",
    "INTENT_MODEL_PATH = '/root/SUSTC_Parking_test/ParkSim/data/smallRegularizedCNN_L0.068_01-29-2022_19-50-35.pth'\n",
    "intent_model = SmallRegularizedCNN()\n",
    "model_state = torch.load(INTENT_MODEL_PATH, map_location=DEVICE)\n",
    "intent_model.load_state_dict(model_state)\n",
    "intent_model.eval().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_extractor = CNNDataProcessor(ds=ds)\n",
    "traj_extractor = TransformerDataProcessor(ds=ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_prediction(multimodal_prediction, inst_centric_view, colors, intent_offsets, save_image_name=\"test.png\"):\n",
    "    sensing_limit = 20\n",
    "    img_size = inst_centric_view.size[0] / 2\n",
    "\n",
    "    plt.cla()\n",
    "\n",
    "    plt.imshow(inst_centric_view)\n",
    "\n",
    "    y_label, _, _, _ = multimodal_prediction[0]\n",
    "\n",
    "    traj_future_pixel = y_label[0, :, :2].detach().cpu().numpy() / \\\n",
    "        sensing_limit*img_size + img_size\n",
    "\n",
    "    plt.plot(traj_future_pixel[:, 0], traj_future_pixel[:, 1], 'wo', linewidth=2, markersize=2)\n",
    "\n",
    "    for prediction, color, offset in zip(reversed(multimodal_prediction), reversed(colors), reversed(intent_offsets)):\n",
    "\n",
    "        _, pred, intent, probability = prediction\n",
    "\n",
    "        intent_pixel = intent[0, 0, :2].detach().cpu().numpy() / \\\n",
    "            sensing_limit*img_size + img_size\n",
    "\n",
    "        traj_pred_pixel = pred[0, :, :2].detach().cpu().numpy() / \\\n",
    "            sensing_limit*img_size + img_size\n",
    "\n",
    "        plt.plot(traj_pred_pixel[:, 0], traj_pred_pixel[:, 1],\n",
    "                 '^', color=color, linewidth=2, markersize=2)\n",
    "        plt.plot(intent_pixel[0], intent_pixel[1],\n",
    "                 '*', color=color, markersize=8)\n",
    "\n",
    "        plt.text(intent_pixel[0]+offset[0], intent_pixel[1]+offset[1],\n",
    "                 f'{probability:.2f}', backgroundcolor=(170/255., 170/255., 170/255., 0.53), color='black', size=7, weight='bold')\n",
    "        print(color, probability)\n",
    "    # 保存图片\n",
    "    plt.savefig(\"/root/SUSTC_Parking_test/temp/\" + save_image_name)\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green 0.24921022355556488\n",
      "green 0.24237677\n",
      "green 0.2490827\n",
      "green 0.2499634\n",
      "green 0.24982819\n",
      "green 0.25008997\n",
      "green 0.25014815\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/SUSTC_Parking_test/ParkSim/python/parksim/trajectory_predict/intent_transformer/my_testing_multimodal.ipynb 单元格 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f7061726b73696d227d/root/SUSTC_Parking_test/ParkSim/python/parksim/trajectory_predict/intent_transformer/my_testing_multimodal.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m frame \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m, frame_token)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f7061726b73696d227d/root/SUSTC_Parking_test/ParkSim/python/parksim/trajectory_predict/intent_transformer/my_testing_multimodal.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m inst_token \u001b[39min\u001b[39;00m frame[\u001b[39m'\u001b[39m\u001b[39minstances\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f7061726b73696d227d/root/SUSTC_Parking_test/ParkSim/python/parksim/trajectory_predict/intent_transformer/my_testing_multimodal.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     multimodal_prediction, inst_centric_view \u001b[39m=\u001b[39m predict_multimodal(\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f7061726b73696d227d/root/SUSTC_Parking_test/ParkSim/python/parksim/trajectory_predict/intent_transformer/my_testing_multimodal.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m         ds, traj_model, intent_model, traj_extractor, intent_extractor, inst_token, \u001b[39mlen\u001b[39;49m(ds\u001b[39m.\u001b[39;49mframes\u001b[39m.\u001b[39;49mkeys())\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, mode\u001b[39m=\u001b[39;49mmode, is_get_trajectory_future\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f7061726b73696d227d/root/SUSTC_Parking_test/ParkSim/python/parksim/trajectory_predict/intent_transformer/my_testing_multimodal.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     ds\u001b[39m.\u001b[39mappend_agent_pred_dpose(inst_token, multimodal_prediction[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f7061726b73696d227d/root/SUSTC_Parking_test/ParkSim/python/parksim/trajectory_predict/intent_transformer/my_testing_multimodal.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     instance \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39minstance\u001b[39m\u001b[39m'\u001b[39m, inst_token)\n",
      "File \u001b[0;32m~/SUSTC_Parking_test/ParkSim/workspace/install/parksim/lib/python3.8/site-packages/parksim/trajectory_predict/intent_transformer/multimodal_prediction.py:132\u001b[0m, in \u001b[0;36mpredict_multimodal\u001b[0;34m(ds, traj_model, intent_model, traj_extractor, intent_extractor, inst_token, inst_idx, n, mode, is_get_trajectory_future)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(output_sequence_length):\n\u001b[1;32m    129\u001b[0m     \u001b[39m# Get source mask\u001b[39;00m\n\u001b[1;32m    130\u001b[0m     tgt_mask \u001b[39m=\u001b[39m generate_square_subsequent_mask(\n\u001b[1;32m    131\u001b[0m         y_input\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mto(DEVICE)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m--> 132\u001b[0m     pred \u001b[39m=\u001b[39m traj_model(img, X,\n\u001b[1;32m    133\u001b[0m                       intent, y_input, tgt_mask)\n\u001b[1;32m    134\u001b[0m     next_item \u001b[39m=\u001b[39m pred[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][:, \u001b[39mNone\u001b[39;00m, :]\n\u001b[1;32m    135\u001b[0m     \u001b[39m# Concatenate previous input with predicted best word\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SUSTC_Parking_test/ParkSim/workspace/install/parksim/lib/python3.8/site-packages/parksim/trajectory_predict/intent_transformer/models/trajectory_predictor_with_decoder_intent_cross_attention.py:175\u001b[0m, in \u001b[0;36mTrajectoryPredictorWithDecoderIntentCrossAttention.forward\u001b[0;34m(self, images_past, trajectories_past, intent, trajectories_future, tgt_mask)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(T_1):\n\u001b[0;32m--> 175\u001b[0m         concat_aligned_img_feature[:, t, :] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcnn(\n\u001b[1;32m    176\u001b[0m             images_past[:, t, :, :, :])\n\u001b[1;32m    178\u001b[0m intent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintentff(intent)\n\u001b[1;32m    180\u001b[0m \u001b[39m# trajectory_history: (N, 10, 3)\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \n\u001b[1;32m    182\u001b[0m \u001b[39m# transformer_input: (N, 10, 18)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "colors = ['darkviolet', 'C1', 'green']\n",
    "intent_offsets = [[-50,0], [0,30], [-50,0]]\n",
    "os.makedirs(f'/root/SUSTC_Parking_test/temp/test', exist_ok=True)\n",
    "smt_vis = SemanticVisualizer(ds, spot_margin=0.3, resolution=0.1, sensing_limit=20, steps=10, stride=10)\n",
    "scene = ds.get('scene', ds.list_scenes()[0])\n",
    "for i in range(1000):\n",
    "    frame_token = scene['last_frame']\n",
    "    frame = ds.get('frame', frame_token)\n",
    "    for inst_token in frame['instances']:\n",
    "        multimodal_prediction, inst_centric_view = predict_multimodal(\n",
    "            ds, traj_model, intent_model, traj_extractor, intent_extractor, inst_token, len(ds.frames.keys())-1, 1, mode=mode, is_get_trajectory_future=False)\n",
    "        ds.append_agent_pred_dpose(inst_token, multimodal_prediction[0][1][0][9].detach().cpu().numpy())\n",
    "        instance = ds.get('instance', inst_token)\n",
    "        agent_token = instance['agent_token']\n",
    "        draw_prediction(multimodal_prediction, inst_centric_view, colors, intent_offsets, save_image_name=f'{agent_token}_{i}.png')\n",
    "    ds.update()\n",
    "    img_frame = smt_vis.plot_frame(frame['frame_token'])\n",
    "    img_frame.transpose(Image.FLIP_TOP_BOTTOM).save(f'/root/SUSTC_Parking_test/temp/test/{i}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = ds.get('scene', ds.list_scenes()[0])\n",
    "frame_index = -1\n",
    "frame = ds.get_future_frames(scene['first_frame'],timesteps=100)[frame_index]\n",
    "inst_token = frame['instances'][9]\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_prediction, inst_centric_view = predict_multimodal(\n",
    "    ds, traj_model, intent_model, traj_extractor, intent_extractor, inst_token, frame_index, 1, mode=mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multimodal_prediction[0][1][0][0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['darkviolet', 'C1', 'green']\n",
    "intent_offsets = [[-50,0], [0,30], [-50,0]]\n",
    "\n",
    "draw_prediction(multimodal_prediction, inst_centric_view,\n",
    "                colors, intent_offsets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = ds.get('scene', ds.list_scenes()[0])\n",
    "frame_index = 2500\n",
    "frame = ds.get_future_frames(scene['first_frame'], timesteps=2700)[frame_index]\n",
    "inst_token = frame['instances'][33]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_prediction, inst_centric_view = predict_multimodal(\n",
    "    ds, traj_model, intent_model, traj_extractor, intent_extractor, inst_token, frame_index, 3, mode=mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['darkviolet', 'C1', 'green']\n",
    "intent_offsets = [[-50, 0], [0, -30], [-50, 0]]\n",
    "\n",
    "draw_prediction(multimodal_prediction, inst_centric_view,\n",
    "                colors, intent_offsets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scene = ds.get('scene', ds.list_scenes()[0])\n",
    "# frame_index = 5900\n",
    "# frame = ds.get_future_frames(scene['first_frame'], timesteps=6000)[frame_index]\n",
    "# inst_token = frame['instances'][37]\n",
    "\n",
    "scene = ds.get('scene', ds.list_scenes()[0])\n",
    "frame_index = 5900\n",
    "frame = ds.get_future_frames(scene['first_frame'], timesteps=6000)[frame_index]\n",
    "inst_token = frame['instances'][20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_prediction, inst_centric_view = predict_multimodal(\n",
    "    ds, traj_model, intent_model, traj_extractor, intent_extractor, inst_token, frame_index, 3, mode=mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['darkviolet', 'C1', 'green']\n",
    "intent_offsets = [[-50, 0], [0, -30], [-50, 0]]\n",
    "\n",
    "draw_prediction(multimodal_prediction, inst_centric_view,\n",
    "                colors, intent_offsets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = ds.get('scene', ds.list_scenes()[0])\n",
    "frame_index = 4000\n",
    "frame = ds.get_future_frames(scene['first_frame'], timesteps=6000)[frame_index]\n",
    "inst_token = frame['instances'][36]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_prediction, inst_centric_view = predict_multimodal(\n",
    "    ds, traj_model, intent_model, traj_extractor, intent_extractor, inst_token, frame_index, 3, mode=mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['darkviolet', 'C1', 'green']\n",
    "intent_offsets = [[-50, 0], [0, -30], [-50, 0]]\n",
    "\n",
    "draw_prediction(multimodal_prediction, inst_centric_view,\n",
    "                colors, intent_offsets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = ds.get('scene', ds.list_scenes()[0])\n",
    "frame_index = 100\n",
    "frame = ds.get_future_frames(scene['first_frame'], timesteps=6000)[frame_index]\n",
    "inst_token = frame['instances'][6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_prediction, inst_centric_view = predict_multimodal(\n",
    "    ds, traj_model, intent_model, traj_extractor, intent_extractor, inst_token, frame_index, 3, mode=mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['darkviolet', 'C1', 'green']\n",
    "intent_offsets = [[-50, 0], [0, -30], [-50, 0]]\n",
    "\n",
    "draw_prediction(multimodal_prediction, inst_centric_view,\n",
    "                colors, intent_offsets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = ds.get('scene', ds.list_scenes()[0])\n",
    "frame_index = 1800\n",
    "frame = ds.get_future_frames(scene['first_frame'], timesteps=6000)[frame_index]\n",
    "# inst_token = frame['instances'][6]\n",
    "inst_token = ds.get_inst_at_location(frame_token=frame['frame_token'], coords=[70, 30])[\n",
    "    'instance_token']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_prediction, inst_centric_view = predict_multimodal(\n",
    "    ds, traj_model, intent_model, traj_extractor, intent_extractor, inst_token, frame_index, 3, mode=mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['darkviolet', 'C1', 'green']\n",
    "intent_offsets = [[-50, 0], [-30, 30], [-50, 0]]\n",
    "\n",
    "draw_prediction(multimodal_prediction, inst_centric_view,\n",
    "                colors, intent_offsets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = ds.get('scene', ds.list_scenes()[0])\n",
    "frame_index = 7010\n",
    "frame = ds.get_future_frames(scene['first_frame'], timesteps=7100)[frame_index]\n",
    "# inst_token = frame['instances'][6]\n",
    "inst_token = ds.get_inst_at_location(frame_token=frame['frame_token'], coords=[15, 30])[\n",
    "    'instance_token']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_prediction, inst_centric_view = predict_multimodal(\n",
    "    ds, traj_model, intent_model, traj_extractor, intent_extractor, inst_token, frame_index, 3, mode=mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['darkviolet', 'C1', 'green']\n",
    "intent_offsets = [[-50, 0], [-30, -30], [10, 30]]\n",
    "\n",
    "draw_prediction(multimodal_prediction, inst_centric_view,\n",
    "                colors, intent_offsets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = ds.get('scene', ds.list_scenes()[0])\n",
    "frame_index = 9000\n",
    "frame = ds.get_future_frames(scene['first_frame'], timesteps=9001)[frame_index]\n",
    "# inst_token = frame['instances'][6]\n",
    "inst_token = ds.get_inst_at_location(frame_token=frame['frame_token'], coords=[35, 65])[\n",
    "    'instance_token']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_prediction, inst_centric_view = predict_multimodal(\n",
    "    ds, traj_model, intent_model, traj_extractor, intent_extractor, inst_token, frame_index, 3, mode=mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['darkviolet', 'C1', 'green']\n",
    "intent_offsets = [[-50, 0], [-30, -20], [-30, -20]]\n",
    "\n",
    "draw_prediction(multimodal_prediction, inst_centric_view,\n",
    "                colors, intent_offsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
